# Credit Card Fraud Detection using Machine Learning and Sampling Techniques

---

## Introduction
Credit card fraud detection is an important problem in machine learning.

In real-world data, fraudulent transactions are very few compared to normal transactions.  
This makes the dataset imbalanced and difficult for machine learning models to learn correctly.

In this assignment, we handle the imbalance problem using different sampling techniques and apply multiple machine learning models.

---

## Dataset
- The credit card fraud detection dataset is **imbalanced**
- Fraud transactions are very few compared to non-fraud transactions

---

## Balancing the Dataset
To handle class imbalance, the following sampling techniques were used:

### 1. Random Under-Sampling
- Reduces the majority class
- Makes both classes equal  
- **Risk:** Loss of useful data

### 2. Random Over-Sampling
- Duplicates minority class samples
- Improves fraud detection  
- **Risk:** Overfitting

### 3. SMOTE (Synthetic Minority Over-sampling Technique)
- Generates synthetic fraud samples
- Preserves data diversity

### 4. NearMiss
- Selects majority samples closest to the minority class
- Performs aggressive under-sampling  
- **Result:** Lower performance observed

### 5. SMOTE-Tomek
- Combination of over-sampling and removal of noisy samples
- Produces a cleaner and well-balanced dataset

---

## Machine Learning Models Implemented
The following models were trained on each of the five sampled datasets:

1. Logistic Regression  
2. Decision Tree  
3. Random Forest  
4. K-Nearest Neighbors (KNN)  
5. Support Vector Machine (SVM)

---

## Model-wise Best Sampling Technique

### M1 – Logistic Regression
- **Best Accuracy:**  
  - Sampling5 (SMOTE-Tomek) → **93.53%**
- **Very Close:**  
  - Sampling3 (SMOTE) → 93.10%
- **Worst Performance:**  
  - Sampling4 (NearMiss) → 18.53%

**Explanation:**  
Logistic Regression benefits from oversampling techniques because they balance the class distribution without losing important data. NearMiss removes too much data, which hurts performance.

---

### M2 – Decision Tree
- **Best Accuracy:**  
  - Sampling2 (Random Over-Sampling) → **98.71%**
  - Sampling3 (SMOTE) → 98.71%
- **Worst Performance:**  
  - Sampling4 (NearMiss) → 15.95%

**Explanation:**  
Decision Trees handle oversampled data well, but aggressive under-sampling removes important patterns.

---

### M3 – Random Forest
- **Best Accuracy:**  
  - Sampling2 (Random Over-Sampling) → **99.14%**
  - Sampling3 (SMOTE) → **99.14%**
- **Worst Performance:**  
  - Sampling4 (NearMiss) → 55.60%

**Explanation:**  
Random Forest performs best with balanced and information-rich datasets, achieved using Random Over-Sampling and SMOTE.

---

### M4 – K-Nearest Neighbors (KNN)
- **Best Accuracy:**  
  - Sampling2 (Random Over-Sampling) → **97.84%**
- **Worst Performance:**  
  - Sampling4 (NearMiss) → 39.66%

**Explanation:**  
KNN is sensitive to data distribution. Oversampling improves neighborhood representation, while undersampling degrades it.

---

### M5 – Support Vector Machine (SVM)
- **Best Accuracy:**  
  - Sampling1 (Random Under-Sampling) → 77.16%  
  - Sampling2 (Random Over-Sampling) → **87.50%**
- **Worst Performance:**  
  - Sampling3 (SMOTE) → 44.40%

**Explanation:**  
SVM struggles with synthetic samples generated by SMOTE and performs better with real data points.

---

## Conclusion
Random Over-Sampling and SMOTE gave the best overall results.

NearMiss performed the worst due to excessive data loss during under-sampling.

Handling class imbalance is crucial for improving fraud detection performance.
